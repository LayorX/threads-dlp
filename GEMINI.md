# Gemini - Threads 影片分析與下載工具

本文件由 Gemini 技術架構師 (Mentor) 負責維護，旨在記錄專案的規劃、狀態、待辦事項與技術決策。

## 專案狀態

*   **階段：** 1.0 - 核心功能穩定版
*   **目前進度：** **專案核心功能已全部完成。** 工具現在能夠透過使用者提供的 Cookie 進行登入，並成功抓取和下載影片。

## 專案概要 (Spec)

打造一個能透過登入使用者帳號，自動蒐集、分析並下載指定 Threads 用戶頁面影片的工具。此工具旨在為內容創作者提供素材與靈感。

### 核心模組規劃

1.  **`scraper.py` (核心模組):**
    *   **認證:** 使用 `selenium-wire` 啟動背景瀏覽器，並透過注入使用者提供的 `sessionid` Cookie 來安全地完成登入認證。
    *   **抓取:** 透過模擬真人滾動頁面，觸發網站載入影片。`selenium-wire` 會攔截所有瀏覽器網路請求。
    *   **分析:** 程式會遍歷所有網路請求，並檢查其回應的 `Content-Type` 標頭。任何類型為 `video/*` 的資源都會被識別為目標影片，並提取其 URL。

2.  **`downloader.py` (下載模組):**
    *   接收 `scraper.py` 提供的影片 URL 列表。
    *   透過 `uv run` 呼叫 `yt-dlp` 引擎，高效、可靠地完成下載任務，並將影片儲存至指定資料夾。

3.  **`main.py` (命令列介面):**
    *   作為專案的統一入口，使用 `argparse` 提供友善的命令列操作介面。
    *   使用者可以指定目標用戶、滾動次數、輸出資料夾等參數。

## 問題解決日誌 (Troubleshooting Log)

這段開發歷程充滿挑戰，我們透過一系列的偵錯與決策，最終抵達成功。這份日誌記錄了我們的思考路徑。

1.  **方案 A: API 方案**
    *   **問題:** 使用者無法申請到官方 Threads API 金鑰。
    *   **決策:** 放棄 API 方案，轉向爬蟲方案。

2.  **方案 B: `yt-dlp` 直接爬取**
    *   **嘗試:** `yt-dlp` 是最強大的通用下載工具，我們首先嘗試用它直接解析 Threads 頁面。
    *   **結果:** 失敗。`yt-dlp` 返回 `Unsupported URL` 錯誤，證實其沒有針對 Threads 的內建解析器。

3.  **方案 C: Selenium + HTML 解析**
    *   **嘗試:** 使用 `Selenium` 模擬瀏覽器打開頁面，並從 HTML 原始碼中尋找 `<video>` 標籤。
    *   **結果:** 失敗。Threads 網站沒有使用簡單的 `<video>` 標籤，此路不通。

4.  **方案 D: Selenium + 網路請求分析 (`.mp4` 過濾)
    *   **嘗試:** 使用 `selenium-wire` 攔截網路請求，並過濾出 URL 結尾是 `.mp4` 的請求。
    *   **結果:** 失敗。匿名訪問時，網站沒有載入任何 `.mp4` 檔案。
    *   **推論:** 必須登入才能看到真正的影片數據。

5.  **方案 E: 登入方案的演進**
    *   **子方案 E1 (帳號密碼):** 最初計畫模擬表單登入，但為了使用者安全，我作為 AI **絕不處理**明文密碼，因此否決了此方案。
    *   **子方案 E2 (Cookie 注入):** 使用者提出了更專業的 Cookie 方案，我們一拍即合。這既安全又可靠。

6.  **依賴地獄 (Dependency Hell) 的挑戰**
    *   在實作 Cookie 方案時，我們遭遇了 `selenium-wire` 的一系列依賴問題。
    *   **`blinker._saferef` 找不到:** 透過分析，發現是 `blinker` 套件版本太新。我們透過在 `pyproject.toml` 中強制鎖定 `blinker==1.7.0` 解決了此問題。
    *   **`pkg_resources` 找不到:** 接著發現缺少 `setuptools` 這個基礎套件。我們透過 `uv add setuptools` 將其加入專案依賴，解決了問題。

7.  **Cookie 注入失敗**
    *   **問題:** 注入 Cookie 時發生 `invalid cookie domain` 錯誤。
    *   **解決:** 移除 `add_cookie` 時手動指定的 `domain` 參數，讓 Selenium 自動處理，問題解決。

8.  **最終的成功**
    *   在解決了所有依賴和程式碼問題後，最終測試成功，程式能夠以登入狀態，透過分析 `Content-Type` 標頭，精準捕獲並下載所有影片。

## 交接手冊與 Todolist

### Phase 1: 核心功能開發 (已全部完成)

- [x] **環境建置:** 初始化 Git 與 Python 虛擬環境 (`uv venv`)。
- [x] **安全設定:** 建立 `.gitignore` 並加入 `.env`，確保憑證安全。
- [x] **安裝依賴:** 使用 `uv add` 與 `uv sync` 成功安裝並鎖定所有必要套件。
- [x] **實作 (爬蟲):** 編寫 `scraper.py`，實現基於 Cookie 認證與 Content-Type 分析的影片抓取邏輯。
- [x] **實作 (下載):** 編寫 `downloader.py`，整合 `yt-dlp` 進行下載。
- [x] **整合 (CLI):** 重構 `main.py`，建立功能完善的命令列介面。
- [x] **完整測試:** 完成端到端測試，確認從抓取到下載的完整流程暢通。

### Phase 2: 擴充與優化 (未來展望)

- [ ] **增加多執行緒:** 研究為下載過程加入多執行緒，以加速大量影片的下載。
- [ ] **錯誤處理強化:** 為網路中斷、Cookie 失效等情況增加更詳細的錯誤提示與重試機制。
- [ ] **AI 增強:** 評估 `Whisper` (語音轉文字), `OpenCV` (影片處理) 等 AI 相關函式庫，為未來增加 AI 功能做準備。
